{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import json\n",
    "import re\n",
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'https://quotes.toscrape.com/'\n",
    "next_page = \"/page/1/\"\n",
    "quotes_list = []\n",
    "author_list = []\n",
    "added_authors = []\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "while next_page:\n",
    "    response = requests.get(url + next_page)\n",
    "    soup = BeautifulSoup(response.text, 'html.parser')\n",
    "\n",
    "    quotes = soup.find_all('span', class_='text')\n",
    "    authors = soup.find_all('small', class_='author')\n",
    "    tags = soup.find_all('div', class_='tags')\n",
    "    \n",
    "    for i in range(0, len(quotes)):\n",
    "        dict_of_quotes = {}\n",
    "        quote_tags = []\n",
    "\n",
    "        tagsforquote = tags[i].find_all('a', class_='tag')\n",
    "        for tagforquote in tagsforquote:\n",
    "            quote_tags.append(tagforquote.text)\n",
    "\n",
    "        dict_of_quotes['tags'] = quote_tags\n",
    "        dict_of_quotes['author'] = authors[i].text\n",
    "        dict_of_quotes['quote'] = quotes[i].text\n",
    "        quotes_list.append(dict_of_quotes)\n",
    "\n",
    "    next_button = soup.find('li', class_='next')\n",
    "    if next_button:\n",
    "        next_page = next_button.find('a')['href']\n",
    "    else:\n",
    "        next_page = None\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('qoutes.json', 'w', encoding='utf=8') as f:\n",
    "    json.dump(quotes_list, f, ensure_ascii=False, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "while next_page:\n",
    "    response = requests.get(url + next_page)\n",
    "    soup = BeautifulSoup(response.text, 'html.parser')\n",
    "\n",
    "    quotes = soup.find_all('span', class_='text')\n",
    "    authors = soup.find_all('small', class_='author')\n",
    "\n",
    "    for author_tag in authors:\n",
    "        dict_of_author = {}\n",
    "\n",
    "        author_name = author_tag.text.strip()\n",
    "        if author_name not in added_authors:\n",
    "\n",
    "            author_link = author_tag.find_next_sibling('a')['href']\n",
    "            author_url = url + author_link\n",
    "\n",
    "            response_author = requests.get(author_url)\n",
    "            author_soup = BeautifulSoup(response_author.text, 'html.parser')\n",
    "\n",
    "            author_title = author_soup.find('h3', class_='author-title').text.strip() if author_soup.find('h3', class_='author-title') else 'N/A'\n",
    "            born_date = author_soup.find('span', class_='author-born-date').text.strip() if author_soup.find('span', class_='author-born-date') else 'N/A'\n",
    "            born_location = author_soup.find('span', class_='author-born-location').text.strip() if author_soup.find('span', class_='author-born-location') else 'N/A'\n",
    "            description = author_soup.find('div', class_='author-description').text.strip() if author_soup.find('div', class_='author-description') else 'N/A'\n",
    "\n",
    "            dict_of_author['fullname'] = author_title\n",
    "            dict_of_author['born_date'] = born_date\n",
    "            dict_of_author['born_location'] = born_location\n",
    "            dict_of_author['description'] = description\n",
    "\n",
    "            author_list.append(dict_of_author)\n",
    "            added_authors.append(author_name)\n",
    "                \n",
    "    next_button = soup.find('li', class_='next')\n",
    "    if next_button:\n",
    "        next_page = next_button.find('a')['href']\n",
    "    else:\n",
    "        next_page = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('authors.json', 'w', encoding='utf=8') as f:\n",
    "    json.dump(author_list, f, ensure_ascii=False, indent=4)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
